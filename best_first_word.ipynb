{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'\n",
    "letter_pos_count = []\n",
    "\n",
    "for letter in alphabet:\n",
    "    for i in range(0, 5):\n",
    "        letter_pos_count.append([letter, i, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_bank.txt') as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "all_words = []\n",
    "\n",
    "for word in lines:\n",
    "    all_words.append(word.strip('\\n'))\n",
    "\n",
    "all_five_letter_words = []\n",
    "\n",
    "for word in all_words:\n",
    "    if (len(word) == 5):\n",
    "        all_five_letter_words.append(word)\n",
    "\n",
    "five_letter_words_no_dup_letters = []\n",
    "for word in all_five_letter_words:\n",
    "    duplicate_found = False\n",
    "    for i in range(0, 4):\n",
    "        if (word[(i + 1):].count(word[i]) > 0):\n",
    "            duplicate_found = True\n",
    "    if duplicate_found == False:\n",
    "        five_letter_words_no_dup_letters.append(word)\n",
    "\n",
    "# print(five_letter_words_no_dup_letters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Letter</th>\n",
       "      <th>Index of Occurrence</th>\n",
       "      <th>Count</th>\n",
       "      <th>Normalized Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>0</td>\n",
       "      <td>611</td>\n",
       "      <td>0.302775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>1782</td>\n",
       "      <td>0.883053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>2</td>\n",
       "      <td>984</td>\n",
       "      <td>0.487611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>3</td>\n",
       "      <td>952</td>\n",
       "      <td>0.471754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a</td>\n",
       "      <td>4</td>\n",
       "      <td>573</td>\n",
       "      <td>0.283944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Letter  Index of Occurrence  Count  Normalized Count\n",
       "0      a                    0    611          0.302775\n",
       "1      a                    1   1782          0.883053\n",
       "2      a                    2    984          0.487611\n",
       "3      a                    3    952          0.471754\n",
       "4      a                    4    573          0.283944"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for word in five_letter_words_no_dup_letters:\n",
    "    for i in range(0, 5):\n",
    "        for l in letter_pos_count:\n",
    "            if (l[0] == word[i] and l[1] == i):\n",
    "                l[2] += 1\n",
    "\n",
    "letter_pos_df = pd.DataFrame(letter_pos_count, columns = ['Letter', 'Index of Occurrence', 'Count', 'Normalized Count'])\n",
    "\n",
    "# Normalize \"Count\" column to create \"Normalized Count\" in df\n",
    "letter_pos_df['Normalized Count'] = (letter_pos_df['Count'] - letter_pos_df['Count'].min()) / (letter_pos_df['Count'].max() - letter_pos_df['Count'].min())\n",
    "letter_pos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_scores = []\n",
    "\n",
    "for word in five_letter_words_no_dup_letters:\n",
    "    score_raw = 0\n",
    "    score_normalized = 0\n",
    "    for i in range(0, 5):\n",
    "        for index, row in letter_pos_df.iterrows():\n",
    "            if (row['Letter'] == word[i] and row['Index of Occurrence'] == i):\n",
    "                score_raw += row['Count']\n",
    "                score_normalized += row['Normalized Count']\n",
    "    words_scores.append([word, score_raw, score_normalized])\n",
    "\n",
    "words_scores_df = pd.DataFrame(words_scores, columns = ['Word', 'Score', 'Normalized Score'])\n",
    "\n",
    "# !!! This cell will take at least 5 minutes to complete !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_word_raw = cares\n",
      "max_pts_raw = 7379\n",
      "max_word_norm = cares\n",
      "max_pts_norm = 3.6565906838453914\n"
     ]
    }
   ],
   "source": [
    "max_word_raw = ''\n",
    "max_pts_raw = 0\n",
    "max_word_norm = ''\n",
    "max_pts_norm = 0\n",
    "for index, row in words_scores_df.iterrows():\n",
    "    if (row['Score'] > max_pts_raw):\n",
    "        max_word_raw = row['Word']\n",
    "        max_pts_raw = row['Score']\n",
    "    if (row['Normalized Score'] > max_pts_norm):\n",
    "        max_word_norm = row['Word']\n",
    "        max_pts_norm = row['Normalized Score']\n",
    "\n",
    "print('max_word_raw = ' + max_word_raw)\n",
    "print('max_pts_raw = ' + str(max_pts_raw))\n",
    "print('max_word_norm = ' + max_word_norm)\n",
    "print('max_pts_norm = ' + str(max_pts_norm))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
